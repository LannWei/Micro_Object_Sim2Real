{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T19:13:03.517067Z",
     "start_time": "2025-01-12T19:13:02.629204Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "import pywt\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T19:13:41.382044Z",
     "start_time": "2025-01-12T19:13:41.371515Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(blurred_frame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                            cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    edges = cv2.Canny(adaptive_thresh, 50, 150)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    closing = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours, gray_frame\n",
    "\n",
    "# Function to process frames for focus measures\n",
    "def process_gray_frame(frame):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "    resized_frame = cv2.resize(blurred_frame, (256, 256))\n",
    "    return resized_frame\n",
    "\n",
    "# Define focus measure functions\n",
    "def laplacian_of_gaussian(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def tenengrad(image):\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    return np.mean(gradient_magnitude)\n",
    "\n",
    "def brenner(image):\n",
    "    shifted_image = np.roll(image, -2, axis=1)\n",
    "    return np.sum((image[:, :-2] - shifted_image[:, :-2])**2)\n",
    "\n",
    "def gray_level_variance(image):\n",
    "    return np.var(image)\n",
    "\n",
    "def entropy(image):\n",
    "    histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    histogram = histogram / histogram.sum()\n",
    "    entropy_value = -np.sum(histogram * np.log2(histogram + 1e-10))\n",
    "    return entropy_value\n",
    "\n",
    "def wavelet_focus_measure(image):\n",
    "    coeffs = pywt.wavedec2(image, 'db1', level=4)\n",
    "    return sum(np.sum(np.abs(coeff)) for coeff in coeffs[1:])\n",
    "\n",
    "def max_absolute_gradient(image):\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    return np.max(np.abs(sobel_x) + np.abs(sobel_y))\n",
    "\n",
    "focus_functions = [\n",
    "    laplacian_of_gaussian,\n",
    "    # tenengrad, brenner,\n",
    "    # gray_level_variance,\n",
    "    # entropy, wavelet_focus_measure,\n",
    "    # max_absolute_gradient\n",
    "]\n",
    "\n",
    "# Segment image into smaller grids\n",
    "def segment_image(image, grid_size):\n",
    "    segments = []\n",
    "    h, w = image.shape\n",
    "    step_h, step_w = h // grid_size[0], w // grid_size[1]\n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            segment = image[i*step_h:(i+1)*step_h, j*step_w:(j+1)*step_w]\n",
    "            segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "# Extract local features from segmented image\n",
    "def extract_local_features(image, grid_size, focus_functions):\n",
    "    segments = segment_image(image, grid_size)\n",
    "    features = []\n",
    "    for segment in segments:\n",
    "        features.extend([func(segment) for func in focus_functions])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T19:13:49.326004Z",
     "start_time": "2025-01-12T19:13:49.177013Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_image_path = \"./xxx/Experiment_Image\"\n",
    "rendering_image_path = \"./xxx/Physical_Rendering_Image/Output\"\n",
    "kinematic_path = \"./xxx/Kinematics_Info\"\n",
    "experiment_image_counts = {}\n",
    "rendering_image_counts = {}\n",
    "\n",
    "for folder_name in os.listdir(experiment_image_path):\n",
    "    folder_path = os.path.join(experiment_image_path, folder_name)\n",
    "    if os.path.isdir(folder_path): \n",
    "        image_count = sum(1 for file in os.listdir(folder_path)\n",
    "                          if file.lower().endswith(('.png', '.jpg', '.jpeg')))\n",
    "        experiment_image_counts[folder_name] = image_count\n",
    "\n",
    "for folder_name in os.listdir(rendering_image_path):\n",
    "    folder_path = os.path.join(rendering_image_path, folder_name)\n",
    "    if os.path.isdir(folder_path): \n",
    "        image_count = sum(1 for file in os.listdir(folder_path)\n",
    "                          if file.lower().endswith(('.png', '.jpg', '.jpeg')))\n",
    "        rendering_image_counts[folder_name] = image_count\n",
    "\n",
    "experiment_min_count = min(experiment_image_counts.values())\n",
    "rendering_min_count = min(rendering_image_counts.values())\n",
    "print(\"min experiment count: \", experiment_min_count)\n",
    "print(\"min rendering count: \", rendering_min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T19:13:59.998016Z",
     "start_time": "2025-01-12T19:13:59.817670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "grid_size=(1, 1)\n",
    "center_crop = transforms.CenterCrop(300)\n",
    "\n",
    "# Output directory for the paired images\n",
    "output_path = \"./xxx/Pix2Pix_All\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def format_folder_name(folder):\n",
    "    parts = folder.split(\"_\")\n",
    "    formatted = f\"P{int(parts[0][1:]):02d}_R{int(parts[1][1:]):02d}\"\n",
    "    return formatted\n",
    "\n",
    "def save_list_to_txt(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(f\"{item}\\n\")\n",
    "\n",
    "for folder_name in os.listdir(experiment_image_path):\n",
    "############################### Process Experiment Data ############################### \n",
    "    print(\"experiment_image_path\", folder_name)\n",
    "    kinematic_file_path = os.path.join(kinematic_path, folder_name + '.txt')\n",
    "    kinematic_values = np.loadtxt(kinematic_file_path)[1:-1]\n",
    "\n",
    "    experiment_folder_path = os.path.join(experiment_image_path, folder_name)\n",
    "    experiment_focus_features = []\n",
    "    for experiment_file_name in os.listdir(experiment_folder_path):\n",
    "        experiment_file_path = os.path.join(experiment_folder_path, experiment_file_name)\n",
    "        \n",
    "        # Read the image\n",
    "        experiment_image = Image.open(experiment_file_path)\n",
    "        experiment_image_np = np.array(experiment_image)\n",
    "        # print(image_np.shape)\n",
    "\n",
    "        experiment_gray_cropped_frame = process_gray_frame(experiment_image_np)\n",
    "\n",
    "        experiment_features = extract_local_features(experiment_gray_cropped_frame, grid_size, focus_functions)\n",
    "        experiment_focus_features.append(experiment_features)\n",
    "\n",
    "    # Combnine experiment_focus_features with depth value (kinematic data)\n",
    "    if len(kinematic_values) != len(experiment_focus_features):\n",
    "        print(f\"Error: Length mismatch! kinematic_values has {len(kinematic_values)} elements, but experiment_focus_features has {len(experiment_focus_features)} elements.\")\n",
    "        break\n",
    "    else:\n",
    "        experiment_focus_features = np.column_stack((experiment_focus_features, kinematic_values))\n",
    "        # print(\"Data combined successfully.\")\n",
    "\n",
    "    experiment_data = np.array(experiment_focus_features)\n",
    "    experiment_data_min = experiment_data.min(axis=0)  # Minimum of each column\n",
    "    experiment_data_max = experiment_data.max(axis=0)  # Maximum of each column\n",
    "    experiment_normalized_data = (experiment_data - experiment_data_min) / (experiment_data_max - experiment_data_min)\n",
    "\n",
    "    # experiment_peaks, _ = find_peaks(experiment_normalized_data[:500,0], height=0.6, distance=10)\n",
    "    # experiment_peak_points = [experiment_normalized_data[i,0] for i in experiment_peaks]\n",
    "\n",
    "    # # Plot the first column\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(experiment_normalized_data[:500,0], label='experiment-0')\n",
    "    # plt.plot(experiment_normalized_data[:500,1], label='kinematic')\n",
    "    # plt.scatter(experiment_peaks, experiment_peak_points, color='r', zorder=5, label=\"Peak Points\")\n",
    "    # plt.ylabel('Value')\n",
    "    # plt.legend(loc='upper left', bbox_to_anchor=(-0.2, 1))\n",
    "    # plt.title('Plot of the First Column')\n",
    "    # plt.show()\n",
    "\n",
    "############################### Process Rendering Data ############################### \n",
    "    rendering_folder_name = format_folder_name(folder_name)\n",
    "    print(\"rendering_image_path\", rendering_folder_name)\n",
    "    rendering_folder_path = os.path.join(rendering_image_path, rendering_folder_name)\n",
    "    rendering_focus_features = []\n",
    "    for rendering_file_name in os.listdir(rendering_folder_path):\n",
    "        rendering_file_path = os.path.join(rendering_folder_path, rendering_file_name)\n",
    "        \n",
    "        # Read the image\n",
    "        rendering_image = Image.open(rendering_file_path)\n",
    "        rendering_image = center_crop(rendering_image)\n",
    "        rendering_image_np = np.array(rendering_image)\n",
    "        # print(image_np.shape)\n",
    "\n",
    "        rendering_blurred_frame = cv2.GaussianBlur(rendering_image_np, (5, 5), 0)\n",
    "        rendering_resized_frame = cv2.resize(rendering_blurred_frame, (256, 256))\n",
    "\n",
    "        rendering_features = extract_local_features(rendering_resized_frame, grid_size, focus_functions)\n",
    "        rendering_focus_features.append(rendering_features)\n",
    "\n",
    "        # plt.figure(figsize=(5, 5))\n",
    "        # plt.imshow(resized_frame, cmap=\"gray\")\n",
    "        # plt.axis('off')  # Hide axes\n",
    "        # plt.title(f\"{folder_name} - {file_name}\")\n",
    "        # plt.show()\n",
    "\n",
    "    rendering_data = np.array(rendering_focus_features)\n",
    "    rendering_data_min = rendering_data.min(axis=0)  # Minimum of each column\n",
    "    rendering_data_max = rendering_data.max(axis=0)  # Maximum of each column\n",
    "    rendering_normalized_data = (rendering_data - rendering_data_min) / (rendering_data_max - rendering_data_min)\n",
    "\n",
    "\n",
    "############################### Data Alignment ############################### \n",
    "    rendering_peak_indices = [0] + [i - 1 for i in range(40, 601, 40)]\n",
    "    rendering_peak_points = [rendering_normalized_data[i] for i in rendering_peak_indices]\n",
    "\n",
    "    experiment_peak_indices, _ = find_peaks(experiment_normalized_data[:,0], height=0.6, distance=10)\n",
    "    experiment_peak_points = [experiment_normalized_data[i,0] for i in experiment_peak_indices]\n",
    "\n",
    "    aligned_rendering_data = []\n",
    "    aligned_experiment_data = []\n",
    "    aligned_experiment_kinetic = []\n",
    "    aligned_rendering_indices = []\n",
    "    aligned_experiment_indices = []\n",
    "\n",
    "    for i in range(len(rendering_peak_indices) - 1):\n",
    "        rendering_start, rendering_end = rendering_peak_indices[i], rendering_peak_indices[i + 1]\n",
    "        experiment_start, experiment_end = experiment_peak_indices[i], experiment_peak_indices[i + 1]\n",
    "\n",
    "        # Number of points in each segment\n",
    "        m = rendering_end - rendering_start\n",
    "        n = experiment_end - experiment_start\n",
    "        # print(i, \": m - \",m, \", n - \",n)\n",
    "\n",
    "        if m < n:\n",
    "            sampled_experiment_indices = np.sort(np.random.choice(range(experiment_start, experiment_end), m, replace=False))\n",
    "            sampled_experiment_points = [experiment_normalized_data[idx, 0] for idx in sampled_experiment_indices]\n",
    "            sampled_experiment_kinetic = [experiment_normalized_data[idx, 1] for idx in sampled_experiment_indices]\n",
    "            rendering_points = rendering_normalized_data[rendering_start:rendering_end, 0]\n",
    "            rendering_indices = list(range(rendering_start, rendering_end))\n",
    "            # selected_experiment_points = np.random.choice(experiment_normalized_data[experiment_peak_indices[i]:experiment_peak_indices[i + 1], 0], m, replace=False).tolist()\n",
    "            # selected_rendering_points = rendering_normalized_data[rendering_peak_indices[i]:rendering_peak_indices[i + 1], 0]\n",
    "        else:\n",
    "            sampled_rendering_indices = np.sort(np.random.choice(range(rendering_start, rendering_end), n, replace=False))\n",
    "            sampled_rendering_points = [rendering_normalized_data[idx, 0] for idx in sampled_rendering_indices]\n",
    "            sampled_experiment_points = experiment_normalized_data[experiment_start:experiment_end, 0]\n",
    "            sampled_experiment_indices = list(range(experiment_start, experiment_end))\n",
    "            sampled_experiment_kinetic = experiment_normalized_data[experiment_start:experiment_end, 1]\n",
    "            rendering_points = sampled_rendering_points\n",
    "            rendering_indices = sampled_rendering_indices\n",
    "\n",
    "            # selected_rendering_points = np.random.choice(rendering_normalized_data[rendering_peak_indices[i]:rendering_peak_indices[i + 1], 0], n, replace=False).tolist()\n",
    "            # selected_experiment_points = experiment_normalized_data[experiment_peak_indices[i]:experiment_peak_indices[i + 1], 0]\n",
    "\n",
    "        aligned_rendering_data.append(rendering_points)\n",
    "        aligned_experiment_data.append(sampled_experiment_points)\n",
    "        aligned_experiment_kinetic.append(sampled_experiment_kinetic)\n",
    "        aligned_rendering_indices.append(rendering_indices)\n",
    "        aligned_experiment_indices.append(sampled_experiment_indices)\n",
    "\n",
    "    # Combine aligned data for visualization\n",
    "    combined_rendering_data = [point for segment in aligned_rendering_data for point in segment]\n",
    "    combined_experiment_data = [point for segment in aligned_experiment_data for point in segment]\n",
    "    combined_experiment_kinetic = [point for segment in aligned_experiment_kinetic for point in segment]\n",
    "    combined_rendering_indices = [point for segment in aligned_rendering_indices for point in segment]\n",
    "    combined_experiment_indices = [point for segment in aligned_experiment_indices for point in segment]\n",
    "\n",
    "    kinetic_output_folder = os.path.join(output_path, \"kinetic\")\n",
    "    os.makedirs(kinetic_output_folder, exist_ok=True)\n",
    "    kinetic_output_file = os.path.join(kinetic_output_folder, f\"kinetic_{folder_name}.txt\")\n",
    "    save_list_to_txt(kinetic_output_file, combined_experiment_kinetic)\n",
    "    print(kinetic_output_file)\n",
    "    \n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(experiment_normalized_data[:500,0], label='experiment-0')\n",
    "    # plt.scatter(experiment_peak_indices, experiment_peak_points, color='r', zorder=5, label=\"Peak Points\")\n",
    "    # # plt.plot(rendering_normalized_data[:,0], label='rendering-0')\n",
    "    # plt.ylabel('Value')\n",
    "    # plt.legend(loc='upper left', bbox_to_anchor=(-0.2, 1))\n",
    "    # plt.title('Original experiment data')\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(rendering_normalized_data[:,0], label='rendering-0')\n",
    "    # plt.scatter(rendering_peak_indices, rendering_peak_points, color='r', zorder=5, label=\"Peak Points\")\n",
    "    # plt.ylabel('Value')\n",
    "    # plt.legend(loc='upper left', bbox_to_anchor=(-0.2, 1))\n",
    "    # plt.title('Original rendering data')\n",
    "    # plt.show() \n",
    "    # print(combined_rendering_indices)\n",
    "    # print(combined_experiment_indices)\n",
    "    # print(len(combined_rendering_data), len(combined_experiment_data))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(combined_rendering_data, label='rendering')\n",
    "    plt.plot(combined_experiment_data, label='experiment')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(-0.2, 1))\n",
    "    plt.title('Aligned data')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "############################### Pired Data Combination ############################### \n",
    "    if len(combined_rendering_indices) != len(combined_experiment_indices):\n",
    "        print(f\"Error: Length mismatch! selected rendering data has {len(combined_rendering_indices)} elements, but selected experiment data has {len(combined_experiment_indices)} elements.\")\n",
    "        break\n",
    "    else:\n",
    "        idx = 0\n",
    "        for rendering_idx, experiment_idx in zip(combined_rendering_indices, combined_experiment_indices):\n",
    "            output_folder = os.path.join(output_path, folder_name)\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "            output_file = os.path.join(output_folder, f\"Paired_{idx+1}.png\")\n",
    "            experiment_image_file = os.path.join(experiment_image_path, folder_name, f\"ANewOT{int(experiment_idx+2):05d}.jpg\")\n",
    "            rendering_image_file = os.path.join(rendering_image_path, rendering_folder_name, f\"Image_{rendering_idx+1}.png\")\n",
    "            # print(output_file, experiment_image_file, rendering_image_file)\n",
    "\n",
    "            rendering_image = Image.open(rendering_image_file).convert(\"RGB\")\n",
    "            rendering_image = center_crop(rendering_image)\n",
    "            experiment_image = Image.open(experiment_image_file).convert(\"RGB\")\n",
    "            # print(rendering_image.size, experiment_image.size)\n",
    "            \n",
    "            rendering_image = rendering_image.resize((256, 256))\n",
    "            experiment_image = experiment_image.resize((256, 256))\n",
    "            # print(rendering_image.size, experiment_image.size)\n",
    "\n",
    "\n",
    "            combined_image = Image.new(\"RGB\", (512, 256))\n",
    "            combined_image.paste(rendering_image, (0, 0))  # Left side\n",
    "            combined_image.paste(experiment_image, (256, 0))  # Right side\n",
    "            # print(combined_image.size)\n",
    "\n",
    "            # plt.figure(figsize=(6, 6))  # Set the figure size\n",
    "            # plt.imshow(combined_image)\n",
    "            # plt.axis(\"off\")  # Turn off the axis\n",
    "            # plt.title(f\"Combined Image: {idx}\")\n",
    "            # plt.show()\n",
    "\n",
    "            # Save the combined image\n",
    "            combined_image.save(output_file)\n",
    "            # print(f\"Saved combined image to {output_file}\")\n",
    "\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################### Draw ###################################\n",
    "# Plot Rendering\n",
    "plt.figure(figsize=(6, 4))\n",
    "x_coords = [0,   20, 60, 100, 140, 180, 220, 250]\n",
    "y_coords = [0.5, 1,   0,   1,   0,   1,   0, 0.75]\n",
    "x_interpolated = np.linspace(min(x_coords), max(x_coords), num=100)  # Higher resolution\n",
    "y_interpolated = np.interp(x_interpolated, x_coords, y_coords)\n",
    "plt.plot(rendering_normalized_data[:250, 0], label='Rendering: Laplacian of Gaussian', c='palevioletred')\n",
    "plt.plot(x_interpolated, y_interpolated, label='Rendering: Normalised Depth', c='orange', linestyle='--')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Image Idx')\n",
    "plt.legend(loc='center left')\n",
    "plt.title('Rendering Image Features')\n",
    "plt.savefig(\"Rendering.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Experiment\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(experiment_normalized_data[:250,0], label='Experiment: Laplacian of Gaussian', c='royalblue')\n",
    "plt.plot(experiment_normalized_data[:250,1], label='Experiment: Normalised Depth', color='orange', linestyle='--')\n",
    "# plt.scatter(experiment_peak_indices, experiment_peak_points, color='r', zorder=5, label=\"Peak Points\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Image Idx')\n",
    "plt.legend(loc='center left') #, bbox_to_anchor=(-0.2, 1)\n",
    "plt.title('Experiment Image Features')\n",
    "plt.savefig(\"Experiment.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Aligned\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(combined_rendering_data[:250], label='Rendering: Laplacian of Gaussian', c='palevioletred')\n",
    "plt.plot(combined_experiment_data[:250], label='Experiment: Laplacian of Gaussian', c='royalblue')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Image Idx')\n",
    "plt.legend(loc='center left')\n",
    "plt.title('Aligned Feature')\n",
    "plt.savefig(\"Aligned.png\")\n",
    "plt.show()\n",
    "############################### Draw ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Split ALL paired images into Train/Val/Test for PixGAN Training\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "source_folder = \"./xxx/Pix2Pix_All\"\n",
    "train_output_folder = \"./xxx/Gen_Model_All/train\"\n",
    "val_output_folder   = \"./xxx/Gen_Model_All/val\"\n",
    "test_output_folder  = \"./xxx/Gen_Model_All/Test\"\n",
    "test_kinematic_output_folder = \"./xxx/Gen_Model_All\"\n",
    "\n",
    "os.makedirs(train_output_folder, exist_ok=True)\n",
    "os.makedirs(val_output_folder, exist_ok=True)\n",
    "os.makedirs(test_output_folder, exist_ok=True)\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "subfolders = [f for f in os.listdir(source_folder) if os.path.isdir(os.path.join(source_folder, f))]\n",
    "\n",
    "train_idx = 1\n",
    "val_idx = 1\n",
    "test_idx = 1\n",
    "\n",
    "test_kinematic_dst = os.path.join(test_kinematic_output_folder, \"test_kinematic.txt\")  \n",
    "aligned_kinematic = []\n",
    "\n",
    "pose_segment = []\n",
    "pose_segment_idx = 0\n",
    "pose_segment_dst = os.path.join(test_kinematic_output_folder, \"pose_segment.txt\")\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    # print(\"***: \", subfolder)\n",
    "    if subfolder == '.ipynb_checkpoints':\n",
    "        # print(subfolder)\n",
    "        continue\n",
    "    \n",
    "    subfolder_path = os.path.join(source_folder, subfolder)\n",
    "    kinematic_file_path = os.path.join(source_folder+\"_kinetic\", \"kinetic_\"+ subfolder + '.txt') #kinetic/kinetic_P60_R70.txt\n",
    "    kinematic_values = np.loadtxt(kinematic_file_path)\n",
    "\n",
    "    files = os.listdir(subfolder_path)\n",
    "    print(kinematic_file_path)\n",
    "    if len(files) != len(kinematic_values):\n",
    "        print(f\"wrong! len(files): {len(files)} != len(kinematic_values): {len(kinematic_values)}\")\n",
    "        break\n",
    "    \n",
    "    combined = list(zip(files, kinematic_values))\n",
    "    random.shuffle(combined)\n",
    "    files, kinematic_values = zip(*combined)\n",
    "    \n",
    "    total_files = len(files)\n",
    "    train_count = int(total_files * train_ratio)\n",
    "    val_count = int(total_files * val_ratio)\n",
    "    \n",
    "    train_files = files[:train_count]\n",
    "    val_files = files[train_count:train_count + val_count]\n",
    "    test_files = files[train_count + val_count:]\n",
    "\n",
    "    train_kinematic = kinematic_values[:train_count]\n",
    "    val_kinematic = kinematic_values[train_count:train_count + val_count]\n",
    "    test_kinematic = kinematic_values[train_count + val_count:]\n",
    "    \n",
    "    # Save Train files\n",
    "    for file, kinematic in zip(train_files, train_kinematic):\n",
    "        src = os.path.join(subfolder_path, file)\n",
    "        dst = os.path.join(train_output_folder, f\"Paired_{train_idx}.png\") \n",
    "        # print(dst)\n",
    "        shutil.copy(src, dst)\n",
    "        train_idx += 1\n",
    "\n",
    "    # Save Val files\n",
    "    for file, kinematic in zip(val_files, val_kinematic):\n",
    "        src = os.path.join(subfolder_path, file)\n",
    "        dst = os.path.join(val_output_folder, f\"Paired_{val_idx}.png\") \n",
    "        shutil.copy(src, dst)\n",
    "        # print(dst)\n",
    "        val_idx += 1\n",
    "    \n",
    "    # Save Test files\n",
    "    for file, kinematic in zip(test_files, test_kinematic):\n",
    "        src = os.path.join(subfolder_path, file)\n",
    "        dst = os.path.join(test_output_folder, f\"Paired_{test_idx}.png\") \n",
    "        shutil.copy(src, dst)\n",
    "        # print(dst)\n",
    "        test_idx += 1\n",
    "\n",
    "    aligned_kinematic.append(test_kinematic)\n",
    "    pose_segment_idx += len(test_files)\n",
    "    pose_segment.append(pose_segment_idx)\n",
    "    print(f\"Processed subfolder: {subfolder}\")\n",
    "    print(f\"Train: {len(train_files)}/{train_idx} files, Val: {len(val_files)}/{val_idx} files, Test: {len(test_files)}/{test_idx} files\")\n",
    "\n",
    "combined_kinematic = [point for segment in aligned_kinematic for point in segment]    \n",
    "print(len(combined_kinematic))\n",
    "save_list_to_txt(test_kinematic_dst, combined_kinematic)\n",
    "save_list_to_txt(pose_segment_dst, pose_segment)\n",
    "print(\"Data split and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Split Part paired images into Train/Val/Test for PixGAN Training\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "source_folder = \"./xxx/Pix2Pix_All\"\n",
    "train_output_folder = \"./xxx/Gen_Model_Part/train\"\n",
    "val_output_folder   = \"./xxx/Gen_Model_Part/val\"\n",
    "test_output_folder  = \"./xxx/Gen_Model_Part/Test\"\n",
    "test_kinematic_output_folder = \"./xxx/Gen_Model_Part\"\n",
    "\n",
    "os.makedirs(train_output_folder, exist_ok=True)\n",
    "os.makedirs(val_output_folder, exist_ok=True)\n",
    "os.makedirs(test_output_folder, exist_ok=True)\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "subfolders = [f for f in os.listdir(source_folder) if os.path.isdir(os.path.join(source_folder, f))]\n",
    "\n",
    "train_idx = 1\n",
    "val_idx = 1\n",
    "test_idx = 1\n",
    "\n",
    "test_kinematic_dst = os.path.join(test_kinematic_output_folder, \"test_kinematic.txt\")  \n",
    "aligned_kinematic = []\n",
    "\n",
    "pose_segment = []\n",
    "pose_segment_idx = 0\n",
    "pose_segment_dst = os.path.join(test_kinematic_output_folder, \"pose_segment.txt\")\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    # print(\"***: \", subfolder)\n",
    "    if subfolder == '.ipynb_checkpoints':\n",
    "        # print(subfolder)\n",
    "        continue\n",
    "    elif subfolder == 'P0_R20':\n",
    "        # print(subfolder)\n",
    "        continue\n",
    "    elif subfolder == 'P10_R30':\n",
    "        # print(subfolder)\n",
    "        continue\n",
    "    elif subfolder == 'P20_R40':\n",
    "        # print(subfolder)\n",
    "        continue\n",
    "    elif subfolder == 'P30_R50':\n",
    "        # print(subfolder)\n",
    "        continue\n",
    "    elif subfolder == 'P40_R60':\n",
    "        # print(subfolder)\n",
    "        continue\n",
    "    \n",
    "    subfolder_path = os.path.join(source_folder, subfolder)\n",
    "    kinematic_file_path = os.path.join(source_folder+\"_kinetic\", \"kinetic_\"+ subfolder + '.txt') #kinetic/kinetic_P60_R70.txt\n",
    "    kinematic_values = np.loadtxt(kinematic_file_path)\n",
    "\n",
    "    files = os.listdir(subfolder_path)\n",
    "    print(kinematic_file_path)\n",
    "    if len(files) != len(kinematic_values):\n",
    "        print(f\"wrong! len(files): {len(files)} != len(kinematic_values): {len(kinematic_values)}\")\n",
    "        break\n",
    "    \n",
    "    combined = list(zip(files, kinematic_values))\n",
    "    random.shuffle(combined)\n",
    "    files, kinematic_values = zip(*combined)\n",
    "    \n",
    "    total_files = len(files)\n",
    "    train_count = int(total_files * train_ratio)\n",
    "    val_count = int(total_files * val_ratio)\n",
    "    \n",
    "    train_files = files[:train_count]\n",
    "    val_files = files[train_count:train_count + val_count]\n",
    "    test_files = files[train_count + val_count:]\n",
    "\n",
    "    train_kinematic = kinematic_values[:train_count]\n",
    "    val_kinematic = kinematic_values[train_count:train_count + val_count]\n",
    "    test_kinematic = kinematic_values[train_count + val_count:]\n",
    "    \n",
    "    # Save Train files\n",
    "    for file, kinematic in zip(train_files, train_kinematic):\n",
    "        src = os.path.join(subfolder_path, file)\n",
    "        dst = os.path.join(train_output_folder, f\"Paired_{train_idx}.png\") \n",
    "        # print(dst)\n",
    "        shutil.copy(src, dst)\n",
    "        train_idx += 1\n",
    "\n",
    "    # Save Val files\n",
    "    for file, kinematic in zip(val_files, val_kinematic):\n",
    "        src = os.path.join(subfolder_path, file)\n",
    "        dst = os.path.join(val_output_folder, f\"Paired_{val_idx}.png\") \n",
    "        shutil.copy(src, dst)\n",
    "        # print(dst)\n",
    "        val_idx += 1\n",
    "    \n",
    "    # Save Test files\n",
    "    for file, kinematic in zip(test_files, test_kinematic):\n",
    "        src = os.path.join(subfolder_path, file)\n",
    "        dst = os.path.join(test_output_folder, f\"Paired_{test_idx}.png\") \n",
    "        shutil.copy(src, dst)\n",
    "        # print(dst)\n",
    "        test_idx += 1\n",
    "\n",
    "    aligned_kinematic.append(test_kinematic)\n",
    "    pose_segment_idx += len(test_files)\n",
    "    pose_segment.append(pose_segment_idx)\n",
    "    print(f\"Processed subfolder: {subfolder}\")\n",
    "    print(f\"Train: {len(train_files)}/{train_idx} files, Val: {len(val_files)}/{val_idx} files, Test: {len(test_files)}/{test_idx} files\")\n",
    "\n",
    "combined_kinematic = [point for segment in aligned_kinematic for point in segment]    \n",
    "print(len(combined_kinematic))\n",
    "save_list_to_txt(test_kinematic_dst, combined_kinematic)\n",
    "save_list_to_txt(pose_segment_dst, pose_segment)\n",
    "print(\"Data split and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separate the test image (of GAN Model Traning) into different pose for Pose Model Traning \n",
    "### Both experiment & generated - ALL/PART\n",
    "#  ./xxx_results_RAL/xxx_PixGAN_All_Data/Test_latest/images\n",
    "#  ./xxx_results_RAL/xxx_PixGAN_Part_Data/Test_latest/images\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "name_folder = \"./xxx/Pix2Pix_All\"\n",
    "# source_folder = \"./pytorch-CycleGAN-and-pix2pix/results/pix2pix_unet_256_lsgan/Test_20/images\"\n",
    "# source_folder = \"./xxx_results_RAL/xxx_PixGAN_All_Data/Test_latest/images\"\n",
    "pose_segment_path = \"./xxx/Gen_Model_All/pose_segment.txt\"\n",
    "experiment_output_path = \"./xxx/Pose_Model/Experiment_All\"\n",
    "# generated_output_path = \"./xxx/Pose_Model/Generated_All\"\n",
    "\n",
    "source_folder = \"./xxx_results_RAL/xxx_PixGAN_Part_Data/Test_latest/images\"\n",
    "# pose_segment_path = \"./xxx/Gen_Model_Part/pose_segment.txt\"\n",
    "# experiment_output_path = \"./xxx/Pose_Model/Experiment_Part\"\n",
    "generated_output_path = \"./xxx/Pose_Model/Generated_Part\"\n",
    "os.makedirs(experiment_output_path, exist_ok=True)\n",
    "os.makedirs(generated_output_path,  exist_ok=True)\n",
    "\n",
    "def read_int_from_txt(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data_scores = [int(line.strip()) for line in f]\n",
    "    return data_scores\n",
    "\n",
    "pose_folder_value = read_int_from_txt(pose_segment_path)\n",
    "pose_folder = [0] + pose_folder_value\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "subfolders = [f for f in os.listdir(name_folder) if os.path.isdir(os.path.join(name_folder, f))]\n",
    "all_files = os.listdir(source_folder)\n",
    "files = [file for file in all_files if file.endswith('fake_B.png')]\n",
    "\n",
    "\n",
    "for i in range(len(pose_folder) - 1):\n",
    "    start_idx = pose_folder[i]\n",
    "    end_idx = pose_folder[i + 1]\n",
    "    idx = start_idx+1\n",
    "    # print(start_idx, end_idx)\n",
    "    pose_name = subfolders[i]\n",
    "    \n",
    "    save_idx = 1\n",
    "    pose_file = files[start_idx:end_idx]\n",
    "    pose_file_len = len(pose_file)\n",
    "\n",
    "    idx = start_idx+1\n",
    "    experiment_dst_folder = os.path.join(experiment_output_path, pose_name)\n",
    "    generated_dst_folder = os.path.join(generated_output_path, pose_name)\n",
    "    os.makedirs(experiment_dst_folder, exist_ok=True)\n",
    "    os.makedirs(generated_dst_folder, exist_ok=True)\n",
    "    for file in pose_file: #[:pose_file_len//2]: # save only half of the images\n",
    "        experiment_src = os.path.join(source_folder, f\"Paired_{idx}_real_B.png\")\n",
    "        generated_src  = os.path.join(source_folder, f\"Paired_{idx}_fake_B.png\")\n",
    "        experiment_dst = os.path.join(experiment_dst_folder, pose_name + f\"_Image_{save_idx}.png\") \n",
    "        generated_dst  = os.path.join(generated_dst_folder, pose_name + f\"_Image_{save_idx}.png\") \n",
    "        # print(experiment_src)\n",
    "        # print(generated_src)\n",
    "        # print(experiment_dst)\n",
    "        # print(generated_dst)\n",
    "        shutil.copy(experiment_src, experiment_dst)\n",
    "        shutil.copy(generated_src, generated_dst)\n",
    "        # print(idx)\n",
    "        \n",
    "        save_idx += 1\n",
    "        idx += 1\n",
    "#     print(save_idx, pose_file_len)\n",
    "print(idx)\n",
    "print(\"All generated test data is separated into pose files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Separate test image into train/val/test for pose estimation\n",
    "# xxx_GAN/xxx/Pose_Model/Experiment_All\n",
    "# xxx_GAN/xxx/Pose_Model/Generated_All\n",
    "# xxx_GAN/xxx/Pose_Model/Generated_Part\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "name_folder = \"./xxx/Pix2Pix_All\"\n",
    "\n",
    "# source_folder = \"./xxx/Pose_Model/Experiment_All\"\n",
    "# train_output_folder = \"./xxx/Pose_Model/Experiment_All_separate/Train\"\n",
    "# val_output_folder   = \"./xxx/Pose_Model/Experiment_All_separate/Val\"\n",
    "# test_output_folder  = \"./xxx/Pose_Model/Experiment_All_separate/Test\"\n",
    "\n",
    "# source_folder = \"./xxx/Pose_Model/Generated_All\"\n",
    "# train_output_folder = \"./xxx/Pose_Model/Generated_All_separate/Train\"\n",
    "# # val_output_folder   = \"./xxx/Pose_Model/Generated_All_separate/Val\"\n",
    "# # test_output_folder  = \"./xxx/Pose_Model/Generated_All_separate/Test\"\n",
    "\n",
    "source_folder = \"./xxx/Pose_Model/Generated_Part\"\n",
    "train_output_folder = \"./xxx/Pose_Model/Generated_Part_separate/Train\"\n",
    "# val_output_folder   = \"./xxx/Pose_Model/Generated_Part_separate/Val\"\n",
    "# test_output_folder  = \"./xxx/Pose_Model/Generated_Part_separate/Test\"\n",
    "\n",
    "os.makedirs(train_output_folder, exist_ok=True)\n",
    "# os.makedirs(val_output_folder, exist_ok=True)\n",
    "# os.makedirs(test_output_folder, exist_ok=True)\n",
    "\n",
    "# train_ratio = 0.84\n",
    "# val_ratio = 0.01\n",
    "# test_ratio = 0.15\n",
    "\n",
    "subfolders = [f for f in os.listdir(source_folder) if os.path.isdir(os.path.join(name_folder, f))]\n",
    "\n",
    "train_idx = 1\n",
    "# val_idx = 1\n",
    "# test_idx = 1\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(source_folder, subfolder)\n",
    "    files = os.listdir(subfolder_path)\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    total_files = len(files)\n",
    "    # train_count = int(total_files * train_ratio)\n",
    "    # val_count = int(total_files * val_ratio)\n",
    "    \n",
    "    train_files = files\n",
    "    # train_files = files[:train_count]\n",
    "    # val_files = files[train_count:train_count + val_count]\n",
    "    # test_files = files[train_count + val_count:]\n",
    "    \n",
    "    # Save Train files\n",
    "    for file in train_files:\n",
    "        if file == '.ipynb_checkpoints':\n",
    "                # print(subfolder)\n",
    "                continue\n",
    "        src = os.path.join(subfolder_path, file)\n",
    "        dst = os.path.join(train_output_folder, file) \n",
    "        # print(src)\n",
    "        shutil.copy(src, dst)\n",
    "        train_idx += 1\n",
    "\n",
    "    # Save Val files\n",
    "    # for file in val_files:\n",
    "    #     if file == '.ipynb_checkpoints':\n",
    "    #             # print(subfolder)\n",
    "    #             continue\n",
    "    #     src = os.path.join(subfolder_path, file)\n",
    "    #     dst = os.path.join(val_output_folder, file) \n",
    "    #     shutil.copy(src, dst)\n",
    "    #     # print(src)\n",
    "    #     val_idx += 1\n",
    "    \n",
    "    # Save Test files\n",
    "    # for file in test_files:\n",
    "    #     if file == '.ipynb_checkpoints':\n",
    "    #             # print(subfolder)\n",
    "    #             continue\n",
    "    #     src = os.path.join(subfolder_path, file)\n",
    "    #     dst = os.path.join(test_output_folder, file) \n",
    "    #     shutil.copy(src, dst)\n",
    "    #     # print(dst)\n",
    "    #     test_idx += 1\n",
    "\n",
    "    print(f\"Processed subfolder: {subfolder}\")\n",
    "    print(f\"Train: {len(train_files)}/{train_idx} files\") #, Val: {len(val_files)}/{val_idx} files, Test: {len(test_files)}/{test_idx} files\")\n",
    "\n",
    "print(\"Data split and saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PixGAN",
   "language": "python",
   "name": "pytorch-cyclegan-and-pix2pix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
